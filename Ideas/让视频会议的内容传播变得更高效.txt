    思科里，经常使用视频录像分享东西。场景如下：
	1. Tech Share的录像分享
	2. 不同国家的团队，展示产品的录像
	3. Training的录像回放
	4. All Hands Meeting的录像回放

    跨国合作，因为时差和不能现场参加会议的问题，用视频录像分享信息十分常用。发布录像也非常简单方便。但是，对于观看方，录像有很多麻烦：
	1. 录像内容密度太低。录像不能随意跳转。一个录像往往很长，想我这样的一个普通工作日，根本不可能完整听一个2小时的录像。视频会议录像也没有办法像文本阅读一样，能够让阅读者查看目录/概要、略读、加快阅读速度、目光查找关键字和跳转。内容密度详略无法直接看见，也不知道视频各段都是讲什么的。
	2. 很多的演讲类视频，其实有意义的画面没几个。PPT演讲的，其实就是把PPT和切换录了下来。讲台演讲的，其实就是在讲台上晃呀晃，除了少数有意义的动作和表情。通常有意义的场景切换都意味着视频画面发生很大变化，其实视频算法完全可以把它们视频出来；而相同的/重重复的/只有无意义的差别的场景，就合并成一张图吧。
	3. 拿来一个all hands meeting的视频，1个半小时。我会思考：如何才能让我马上知道这个视频的要点？我要怎么知道all hands meeting到底讲了什么要点？
	4. 总之，视频分享的内容阅读效率问题。

    那么如何解决呢？可以考虑用语音识别，把视频转换成文章。视频画面，算法合并冗余重复的场景，变成连环画，与文章关联起来。视频中还需要保留为视频/动画的地方，变成文章的嵌入小视频段。
    利用这种自动转换方法，为每个视频附带一个上述内容文章。

=============== 2013-11-12 ==============

1. 捕捉演讲者的谈话间隔。
   比如，每个ppt换页，往往配合着演讲者的谈话间隔。